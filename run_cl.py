import os
import sys
import subprocess
import logging
import shutil

# ================= å¯¦é©—é…ç½® (Configuration) =================

# 1. å¯¦é©—ç¨®å­
SEEDS = [438, 689, 251, 744, 329]

# 2. åŸºç¤æ¨¡å‹è·¯å¾‘
BASE_MODEL = "./initial_model/t5-large"

# 3. è³‡æ–™å¤¾è¨­å®š
DATA_ROOT = "./CL_Benchmark"
RESULTS_ROOT = "O-LoRA"

# 4. è³‡æ–™é›†èˆ‡ä»»å‹™é¡å‹çš„æ˜ å°„
DATASET_TASK_MAP = {
    "dbpedia": "TC",
    "amazon":  "SC",
    "yahoo":   "TC",
    "agnews":  "TC"
}

# 5. ä»»å‹™é †åº (Order 1)
TASK_ORDER = ["dbpedia", "amazon", "yahoo", "agnews"]

# 6. è¨“ç·´åƒæ•¸
COMMON_ARGS = {
    "--adapter_type": "LoRA",
    "--dynamic_expansion": "",     # ç©ºå­—ä¸²ä»£è¡¨ True
    "--num_experts": "4",          # é è¨­å€¼ 4
    "--expert_rank": "8",          # é è¨­å€¼ 8
    "--top_k": "2",                # é è¨­å€¼ 2
    "--num_epochs": "1",           # O-LoRA é è¨­å€¼ 1ï¼ŒOrthMoE é è¨­å€¼ 3
    "--lr": "1e-3",                # O-LoRA é è¨­å€¼ 1e-3ï¼ŒOrthMoE é è¨­å€¼ 5e-4
    "--batch_size": "8",
    "--accumulation_steps": "8",
    "--lambda_orth": "0.5",
    "--lambda_balance": "0.0",
    "--max_input_length": "256",   # O-LoRA é è¨­å€¼ 512 (OOM)ï¼ŒOrthMoE é è¨­å€¼ 256
    "--max_label_length": "50",
    # "--debug": ""                  # ç©ºå­—ä¸²ä»£è¡¨ True
}

# ==========================================================

def setup_cl_logger(results_root):
    """
    è¨­å®š run_cl.py å°ˆç”¨çš„ Loggerï¼Œè·¯å¾‘: results/cl.log
    """
    log_file = os.path.join(results_root, "cl.log")
    logger = logging.getLogger("CL_Runner")
    logger.setLevel(logging.INFO)
    
    # æ¸…ç©ºä¹‹å‰çš„ Handler
    if logger.handlers:
        logger.handlers.clear()

    formatter = logging.Formatter('%(asctime)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

    # 1. File Handler (å¯«å…¥æª”æ¡ˆ)
    fh = logging.FileHandler(log_file, mode='a', encoding='utf-8') # mode='w' æ¯æ¬¡é‡è·‘è©² seed è¦†è“‹èˆŠ log
    fh.setFormatter(formatter)
    logger.addHandler(fh)

    # 2. Stream Handler (è¼¸å‡ºåˆ°çµ‚ç«¯æ©Ÿ)
    sh = logging.StreamHandler(sys.stdout)
    sh.setFormatter(formatter)
    logger.addHandler(sh)

    return logger

def run_subprocess(command, cl_logger, seed_log_path):
    """
    ä½¿ç”¨ subprocess åŸ·è¡Œ main.pyï¼Œä¸¦å°‡è©³ç´°è¼¸å‡º: results/{seed}/run.log
    """
    # å°‡ list è½‰ç‚ºå­—ä¸²æ–¹ä¾¿é–±è®€ log
    cmd_str = " ".join(command)
    cl_logger.info(f"åŸ·è¡ŒæŒ‡ä»¤: {cmd_str}")

    with open(seed_log_path, 'a', encoding='utf-8') as seed_logger:

        seed_logger.write(f"\n{'='*20} Executing Command {'='*20}\n")
        seed_logger.write(f"{cmd_str}\n")
        seed_logger.write(f"{'='*59}\n\n")

        process = subprocess.Popen(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT, # å°‡éŒ¯èª¤è¼¸å‡ºåˆä½µåˆ°æ¨™æº–è¼¸å‡º
            text=True,
            bufsize=1
        )

        # å³æ™‚è®€å–è¼¸å‡º
        for line in process.stdout:
            sys.stdout.write(line)
            seed_logger.write(line)
            seed_logger.flush()
        
        process.wait()
    
    if process.returncode != 0:
        cl_logger.error(f"âŒ ä»»å‹™åŸ·è¡Œå¤±æ•— (Return Code: {process.returncode})")
        raise RuntimeError("Subprocess failed")
    else:
        cl_logger.info("âœ… ä»»å‹™åŸ·è¡ŒæˆåŠŸ")

def main():
    # ç¢ºä¿æ ¹è¼¸å‡ºç›®éŒ„å­˜åœ¨
    os.makedirs(RESULTS_ROOT, exist_ok=True)

    # è¨­å®š order logger (results/cl.log)
    cl_logger = setup_cl_logger(RESULTS_ROOT)

    cl_logger.info("="*52)
    cl_logger.info(f"Seeds: {SEEDS}")
    cl_logger.info(f"Order: {TASK_ORDER}")

    for seed in SEEDS:
        cl_logger.info(f"============ Start Processing Seed: {seed} ============\n")

        # å®šç¾©è©² Seed çš„çµæœç›®éŒ„: results/{seed}
        seed_dir = os.path.join(RESULTS_ROOT, str(seed))

        # æ¸…ç©ºèˆŠçš„ Seed ç›®éŒ„
        if os.path.exists(seed_dir):
            cl_logger.warning(f"[System] åµæ¸¬åˆ°èˆŠçš„ Seed ç›®éŒ„ï¼Œæ­£åœ¨æ¸…ç©º: {seed_dir}\n")
            shutil.rmtree(seed_dir)

        # å»ºç«‹ç›®éŒ„ results/{seed}
        os.makedirs(seed_dir, exist_ok=True)

        # å®šç¾© main.py çš„è©³ç´° Log è·¯å¾‘: results/{seed}/run.log
        seed_log_path = os.path.join(seed_dir, "run.log")

        # æ¸…ç©ºæˆ–æ˜¯å»ºç«‹æ–°çš„ seed run.log (è‹¥æ˜¯é‡è·‘ï¼Œå…ˆæ¸…ç©ºèˆŠçš„)
        with open(seed_log_path, 'w', encoding='utf-8') as f:
            pass

        # å®šç¾©åœ–ç‰‡ç›®éŒ„: results/{seed}/all_plots
        all_plots = os.path.join(seed_dir, "all_plots")
        os.makedirs(all_plots, exist_ok=True)

        # åˆå§‹åŒ– CL ç‹€æ…‹è®Šæ•¸
        previous_model_path = None
        accumulated_test_data = []
        accumulated_test_labels = []

        for step, dataset_name in enumerate(TASK_ORDER):
            task_type = DATASET_TASK_MAP.get(dataset_name)
            if not task_type:
                cl_logger.error(f"æ‰¾ä¸åˆ°è³‡æ–™é›† {dataset_name} çš„ä»»å‹™é¡å‹æ˜ å°„ï¼")
                return

            cl_logger.info(f">>> [Step {step+1}/{len(TASK_ORDER)}] Dataset: {dataset_name} ({task_type})")

            # 1. æº–å‚™è·¯å¾‘
            dataset_path = os.path.join(DATA_ROOT, task_type, dataset_name)
            train_file = os.path.join(dataset_path, "train.json")
            eval_file = os.path.join(dataset_path, "dev.json")
            test_file = os.path.join(dataset_path, "test.json")
            labels_file = os.path.join(dataset_path, "labels.json")

            # å®šç¾©è¼¸å‡ºç›®éŒ„: results/{seed}/{dataset_name}
            output_dir = os.path.join(seed_dir, dataset_name)
            os.makedirs(output_dir, exist_ok=True)

            # å®šç¾©è©²ä»»å‹™çš„åœ–ç‰‡ç›®éŒ„: results/{seed}/all_plots/{dataset_name}
            task_plot_dir = os.path.join(all_plots, dataset_name)
            os.makedirs(task_plot_dir, exist_ok=True)
            
            # 2. ç´¯ç©æ¸¬è©¦è³‡æ–™ (Accumulated Testing)
            accumulated_test_data.append(test_file)
            accumulated_test_labels.append(labels_file)

            # 3. çµ„åˆ Command
            cmd = [
                "python", "main.py",
                "--data_file", train_file,
                "--labels_file", labels_file,
                "--eval_file", eval_file,
                "--eval_labels_files", labels_file,
                "--output_dir", output_dir,
                "--plot_dir", task_plot_dir,
                "--dataset_name", dataset_name,
                "--base_model_name", BASE_MODEL,
                "--seed", str(seed)
            ]

            # åŠ å…¥é€šç”¨åƒæ•¸
            for k, v in COMMON_ARGS.items():
                cmd.append(k)
                if v: # å¦‚æœæœ‰å€¼å°±åŠ ï¼Œå¦‚æœæ˜¯ flag (ç©ºå­—ä¸²) ä¹ŸåŠ  key
                    cmd.append(v)

            # [CL é—œéµ] æ¨¡å‹è·¯å¾‘è™•ç†
            if previous_model_path:
                # Task 2+: ä½¿ç”¨ä¸Šä¸€å€‹ä»»å‹™è¨“ç·´å¥½çš„æ¨¡å‹
                cmd.extend(["--model_path", previous_model_path])
            else:
                # Task 1: ä¸åŠ  --model_pathï¼Œmain.py æœƒè®€å– base_model_name
                pass

            # [CL é—œéµ] æ¸¬è©¦è³‡æ–™åˆ—è¡¨ (åŒ…å«éå»æ‰€æœ‰ä»»å‹™ + ç•¶å‰ä»»å‹™)
            if accumulated_test_data:
                cmd.append("--test_data_files")
                cmd.extend(accumulated_test_data)
                cmd.append("--test_labels_files")
                cmd.extend(accumulated_test_labels)

            # 4. åŸ·è¡Œè¨“ç·´
            try:
                run_subprocess(cmd, cl_logger, seed_log_path)
                
                # æ›´æ–° previous_model_path ç‚ºç•¶å‰è¼¸å‡ºçš„æ¨¡å‹ï¼Œä¾›ä¸‹ä¸€å€‹ä»»å‹™ä½¿ç”¨
                previous_model_path = output_dir
                cl_logger.info(f"âœ… {dataset_name} è¨“ç·´å®Œæˆã€‚æ¨¡å‹å·²å„²å­˜è‡³: {output_dir}\n")

            except RuntimeError:
                cl_logger.error(f"â›” Seed {seed} åœ¨ä»»å‹™ {dataset_name} ä¸­æ–·ã€‚åœæ­¢è©² Seed çš„å¾ŒçºŒä»»å‹™ã€‚")
                break # è·³å‡º dataset loopï¼Œç¹¼çºŒä¸‹ä¸€å€‹ seed

        cl_logger.info(f"================ Seed {seed} Finished! ================\n")

    cl_logger.info("ğŸ‰ æ‰€æœ‰å¯¦é©—åŸ·è¡Œå®Œç•¢ï¼\n")

if __name__ == "__main__":
    main()